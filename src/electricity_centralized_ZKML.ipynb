{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb67701",
   "metadata": {},
   "source": [
    "## Load an LTSF-Linear Model\n",
    "\n",
    "Train the model through 'electricity.sh' bash script.\n",
    "Load an .pth file from the checkpoints folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95613ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (Linear): ModuleList(\n",
      "    (0-320): 321 x Linear(in_features=192, out_features=24, bias=True)\n",
      "  )\n",
      ") with 1486872 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/zkpet/venv/lib/python3.11/site-packages/torch/_tensor.py:836: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  10.5662,   81.9392,    7.4823,  ..., 2459.0837,  602.2404,\n",
      "          2610.2004],\n",
      "         [  10.6349,   76.0962,    7.8692,  ..., 2268.2991,  435.5055,\n",
      "          2588.4624],\n",
      "         [  10.5574,   71.5558,    8.1297,  ..., 2088.3269,  273.8727,\n",
      "          2635.1079],\n",
      "         ...,\n",
      "         [  11.2245,   87.8995,    8.0196,  ..., 1684.2798,  147.4261,\n",
      "          2536.6782],\n",
      "         [  10.3803,   84.7001,    8.0491,  ..., 2226.7456,  233.7020,\n",
      "          2515.1611],\n",
      "         [  10.5372,   79.9100,    8.1474,  ..., 2274.9666,  210.1272,\n",
      "          2471.6387]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models.DLinear import Model as DLinear\n",
    "from models.Linear import Model as Linear\n",
    "from models.NLinear import Model as NLinear\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "      self.seq_len = seq_len\n",
    "      self.pred_len = pred_len\n",
    "      self.enc_in = 321\n",
    "      self.individual = True\n",
    "\n",
    "model = 'Linear'\n",
    "# target = '40'\n",
    "seq_len = 192\n",
    "pred_len = 24\n",
    "\n",
    "configs = Configs(seq_len, pred_len)\n",
    "match model:\n",
    "  case 'Linear':\n",
    "    circuit = Linear(configs)\n",
    "  case 'DLinear':\n",
    "    circuit = DLinear(configs)\n",
    "  case 'NLinear':\n",
    "    circuit = NLinear(configs)\n",
    "\n",
    "# basepath = '../checkpoints/Electricity_{}_{}_{}_custom_ftS_tg{}_sl{}_ll48_pl{}_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0/checkpoint.pth'\n",
    "check_point_model = '../checkpoints/Electricity_192_24_Linear_custom_ftM_sl192_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0/checkpoint.pth'\n",
    "\n",
    "\n",
    "state_dict = torch.load(check_point_model)\n",
    "circuit.load_state_dict(state_dict)\n",
    "\n",
    "total_params = sum(\n",
    "\tparam.numel() for param in circuit.parameters()\n",
    ")\n",
    "\n",
    "print(circuit, 'with {} parameters'.format(total_params))\n",
    "\n",
    "df = pd.read_csv('../dataset/electricity.csv')\n",
    "# Load the last seq_len entries data as input and converts to tensor\n",
    "x = torch.tensor(df[-seq_len:].drop(labels=['date'], axis=1).values, requires_grad=True).resize(1, seq_len, len(df.columns) - 1).float()\n",
    "# Flips the neural net into inference mode\n",
    "circuit.eval()\n",
    "\n",
    "y = circuit(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a18bb",
   "metadata": {},
   "source": [
    "## ZK Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Files Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37637c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "import os\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "model_path = os.path.join('network.onnx')\n",
    "compiled_model_path = os.path.join('network.ezkl')\n",
    "pk_path = os.path.join('test.pk')\n",
    "vk_path = os.path.join('test.vk')\n",
    "settings_path = os.path.join('settings.json')\n",
    "srs_path = os.path.join('kzg.srs')\n",
    "witness_path = os.path.join('witness.json')\n",
    "data_path = os.path.join('input.json')\n",
    "proof_path = os.path.join('test.pf')\n",
    "sol_code_path = os.path.join('verify.sol')\n",
    "abi_path = os.path.join('verify.abi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d388ec",
   "metadata": {},
   "source": [
    "#### Convert Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82db373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input.json size: 433.103515625KB\n",
      "network.onnx size: 7601.50390625KB\n"
     ]
    }
   ],
   "source": [
    "# Model was trained by 'electricity.sh' and stored into the checkpoint state 'checkpoint.pth'.\n",
    "# Now we need to export the onnx file from this state file with model inputs.\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(circuit,               # model being run\n",
    "                  x,                   # model input (or a tuple for multiple inputs)\n",
    "                  model_path,            # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=15,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "\n",
    "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "# Serialize data into file:\n",
    "json.dump( data, open(data_path, 'w' ))\n",
    "\n",
    "input_size = os.stat(data_path).st_size / 1024\n",
    "onnx_size = os.stat(model_path).st_size / 1024\n",
    "print(\"Input.json size: {}KB\".format(input_size))\n",
    "print(\"network.onnx size: {}KB\".format(onnx_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be271e27",
   "metadata": {},
   "source": [
    "### Setting circuit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4449eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "\n",
    "run_args = ezkl.PyRunArgs()\n",
    "run_args.input_visibility = \"private\"\n",
    "run_args.output_visibility = \"public\"\n",
    "run_args.param_visibility = \"fixed\"\n",
    "run_args.variables = [(\"batch_size\", 1)]\n",
    "# run_args.logrows = 20\n",
    "\n",
    "try:\n",
    "    table_string = ezkl.table(model_path, run_args)\n",
    "#     print(table_string)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "using column duplication for 1 fixed columns\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+------------+---------------+-----------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error  | max_error | min_error   | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+---------------+-----------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| -0.0441972 | -0.0005235672 | 82.31641  | -117.953125 | 0.8490563      | 0.0005235672     | 117.953125    | 0             | 18.144827          | -0.000017032942    | 0.001434191            |\n",
      "+------------+---------------+-----------+-------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n",
    "assert res == True\n",
    "\n",
    "res = ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e11b202",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7b28aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation time used: 8.938970184004575 seconds.\n",
      "Current memory size 1133.075 KB, peak memory size 1158.369 KB\n"
     ]
    }
   ],
   "source": [
    "tracemalloc.start()\n",
    "start = timer()\n",
    "\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "assert res == True\n",
    "\n",
    "end = timer()\n",
    "print(\"Compilation time used: {} seconds.\".format(end - start))\n",
    "\n",
    "curr_size, peak_size = tracemalloc.get_traced_memory()\n",
    "print(\"Current memory size {} KB, peak memory size {} KB\".format(round(curr_size / 1024, 3),\n",
    "                                                              round(peak_size / 1024, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0323dc",
   "metadata": {},
   "source": [
    "### Creating the circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5e374a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thread '<unnamed>' panicked at /root/.cargo/git/checkouts/halo2-049b997cf7195aea/4d7e6dd/halo2_proofs/src/poly/domain.rs:55:9:\n",
      "extended_k (29, k=26, j=6) with degree (335544320) must be <= S (28), the size of the field\n"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "extended_k (29, k=26, j=6) with degree (335544320) must be <= S (28), the size of the field",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Setup is performed by the application developer, \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# who then deploys the resulting artifacts to production.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# setup the circuit and make sure the keys are generated afterwards. \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mezkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompiled_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvk_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpk_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrs_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(vk_path)\n",
      "\u001b[0;31mPanicException\u001b[0m: extended_k (29, k=26, j=6) with degree (335544320) must be <= S (28), the size of the field"
     ]
    }
   ],
   "source": [
    "# Setup is performed by the application developer, \n",
    "# who then deploys the resulting artifacts to production.\n",
    "\n",
    "# get public srs from kzg ceremony, saved to srs path. \n",
    "res = ezkl.get_srs(srs_path=srs_path, settings_path=settings_path)\n",
    "\n",
    "# setup the circuit and make sure the keys are generated afterwards. \n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577a100",
   "metadata": {},
   "source": [
    "### Making a proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 2\n",
      "spawning module 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 4.010687675327063 seconds\n",
      "[ Top 10 ]\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:2200: size=64.6 MiB, count=6, average=10.8 MiB\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234: size=1753 KiB, count=26424, average=68 B\n",
      "/tmp/ipykernel_1398943/790744412.py:5: size=943 KiB, count=6402, average=151 B\n",
      "/tmp/ipykernel_1398943/790744412.py:10: size=73.6 KiB, count=1241, average=61 B\n",
      "/usr/lib/python3.10/tracemalloc.py:558: size=68.1 KiB, count=1295, average=54 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/IPython/core/compilerop.py:174: size=66.9 KiB, count=739, average=93 B\n",
      "/usr/lib/python3.10/posixpath.py:373: size=63.5 KiB, count=510, average=128 B\n",
      "/usr/lib/python3.10/tracemalloc.py:67: size=58.1 KiB, count=929, average=64 B\n",
      "/usr/lib/python3.10/tracemalloc.py:505: size=52.2 KiB, count=948, average=56 B\n",
      "/usr/lib/python3.10/abc.py:123: size=48.9 KiB, count=534, average=94 B\n",
      "test.pf size: 22.4736328125KB\n"
     ]
    }
   ],
   "source": [
    "# Prove, invoked with ezkl prove at the cli or ezkl.prove() in Python, is called by the prover, often on the client.\n",
    "\n",
    "# the witness data for the claim: an (input, output) pair (x,y) such that model(input) = output.\n",
    "# this pair can be produced from x using the gen-witness command.\n",
    "# now generate the witness file \n",
    "\n",
    "tracemalloc.start()\n",
    "start = timer()\n",
    "res = ezkl.gen_witness(\n",
    "        data_path, \n",
    "        compiled_model_path, \n",
    "        witness_path\n",
    "      )\n",
    "assert os.path.isfile(witness_path)\n",
    "\n",
    "# GENERATE A PROOF\n",
    "\n",
    "res = ezkl.prove(\n",
    "        witness_path,\n",
    "        compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "        \"single\",\n",
    "        srs_path\n",
    "    )\n",
    "\n",
    "# print(res)\n",
    "# assert os.path.isfile(proof_path)\n",
    "\n",
    "end = timer()\n",
    "prove_time = end - start\n",
    "print(\"time used: {} seconds\".format(prove_time))\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('lineno')\n",
    "print(\"[ Top 10 ]\")\n",
    "for stat in top_stats[:10]:\n",
    "    print(stat)\n",
    "\n",
    "proof_size = os.stat(proof_path).st_size / 1024\n",
    "print(\"{} size: {}KB\".format(proof_path, proof_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ab53a",
   "metadata": {},
   "source": [
    "### Verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068394b4",
   "metadata": {},
   "source": [
    "#### VERIFY off-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f00d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified\n",
      "time used: 0.02605723962187767 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "print(\"verified\")\n",
    "end = timer()\n",
    "print(\"time used: {} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2273575",
   "metadata": {},
   "source": [
    "#### VERIFY on-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb7d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify.sol size: 58.140625KB\n"
     ]
    }
   ],
   "source": [
    "# Create verifier contract\n",
    "res = ezkl.create_evm_verifier(\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "        settings_path,\n",
    "        sol_code_path,\n",
    "        abi_path,\n",
    "    )\n",
    "verifier_size = os.stat(sol_code_path).st_size / 1024\n",
    "print(\"{} size: {}KB\".format(sol_code_path, verifier_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8fed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the verifier contract onchain\n",
    "sol_code_path = os.path.join(\"verify.sol\")\n",
    "address_path = os.path.join('contractAddr.txt')\n",
    "# assuming anvil is running\n",
    "res = ezkl.deploy_evm(\n",
    "    address_path,\n",
    "    sol_code_path,\n",
    "    'http://127.0.0.1:3030'\n",
    ")\n",
    "\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify proof onchain\n",
    "\n",
    "with open(address_path, 'r') as f:\n",
    "  addr = f.readline()\n",
    "\n",
    "res = ezkl.verify_evm(\n",
    "    proof_path,\n",
    "    addr,\n",
    "    'http://127.0.0.1:3030'\n",
    ")\n",
    "\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.json size: 5.643KB\n",
      "network.onnx size: 68.064KB\n",
      "test.pf size: 22.474KB\n",
      "prove time used: 4.011 seconds\n",
      "verify.sol size: 58.141KB\n",
      "Verifier bytecode size: 13.741KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "input_size = np.round(os.stat(data_path).st_size / 1024, 3)\n",
    "onnx_size = np.round(os.stat(model_path).st_size / 1024, 3)\n",
    "print(\"{} size: {}KB\".format(data_path, input_size))\n",
    "print(\"{} size: {}KB\".format(model_path, onnx_size))\n",
    "proof_size = np.round(os.stat(proof_path).st_size / 1024, 3)\n",
    "print(\"{} size: {}KB\".format(proof_path, proof_size))\n",
    "print(\"prove time used: {} seconds\".format(np.round(prove_time, 3)))\n",
    "verifier_size = np.round(os.stat(sol_code_path).st_size / 1024, 3)\n",
    "print(\"{} size: {}KB\".format(sol_code_path, verifier_size))\n",
    "\n",
    "p = Popen([\"solc\", \"--bin\", \"--optimize\", \"verify.sol\"], stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "output, err = p.communicate(b\"input data that is passed to subprocess' stdin\")\n",
    "verifier_code_size = np.round(sys.getsizeof((output.split(b'\\n')[3])) / 1000, 3)\n",
    "print(\"Verifier bytecode size: {}KB\".format(verifier_code_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "677d955a7e2fda1ccedeccccaf5b6288055c92ed57fa8a7738e9fddc38d3c4eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
