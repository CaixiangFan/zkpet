{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb67701",
   "metadata": {},
   "source": [
    "## Load an LTSF-Linear Model\n",
    "\n",
    "Train the model through 'electricity.sh' bash script.\n",
    "Load an .pth file from the checkpoints folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95613ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (Linear): ModuleList(\n",
      "    (0-49): 50 x Linear(in_features=192, out_features=24, bias=True)\n",
      "  )\n",
      ") with 231600 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/zkpet/venv/lib/python3.11/site-packages/torch/_tensor.py:836: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 10.4050,  80.6632,   7.6226,  ..., 197.5994,  74.7061, 612.8615],\n",
      "         [ 10.5257,  76.0636,   7.9764,  ..., 182.8274,  49.7463, 515.0209],\n",
      "         [ 10.4413,  72.1204,   8.0914,  ..., 172.0903,  36.8496, 461.4332],\n",
      "         ...,\n",
      "         [ 11.3484,  88.4742,   7.7014,  ..., 236.9456,  61.0505, 713.3558],\n",
      "         [ 10.4254,  85.9661,   7.8380,  ..., 221.0525,  82.6110, 641.0234],\n",
      "         [ 10.3827,  82.7221,   8.1247,  ..., 209.1553,  67.1848, 576.4092]]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from models.DLinear import Model as DLinear\n",
    "from models.Linear import Model as Linear\n",
    "from models.NLinear import Model as NLinear\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len, enc_in):\n",
    "      self.seq_len = seq_len\n",
    "      self.pred_len = pred_len\n",
    "      self.enc_in = enc_in\n",
    "      self.individual = True\n",
    "\n",
    "model = 'Linear'\n",
    "enc_in = 50\n",
    "seq_len = 192\n",
    "pred_len = 24\n",
    "\n",
    "configs = Configs(seq_len, pred_len, enc_in)\n",
    "match model:\n",
    "  case 'Linear':\n",
    "    circuit = Linear(configs)\n",
    "  case 'DLinear':\n",
    "    circuit = DLinear(configs)\n",
    "  case 'NLinear':\n",
    "    circuit = NLinear(configs)\n",
    "\n",
    "basepath = '../checkpoints/Electricity_192_24_Linear_custom_ftM_sl192_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0'\n",
    "newpath = basepath + '_{}'.format(enc_in)\n",
    "if os.path.isdir(basepath):\n",
    "  os.rename(basepath, newpath)\n",
    "\n",
    "check_point_model = os.path.join(newpath, 'checkpoint.pth')\n",
    "\n",
    "state_dict = torch.load(check_point_model)\n",
    "circuit.load_state_dict(state_dict)\n",
    "\n",
    "total_params = sum(\n",
    "\tparam.numel() for param in circuit.parameters()\n",
    ")\n",
    "\n",
    "print(circuit, 'with {} parameters'.format(total_params))\n",
    "\n",
    "df = pd.read_csv('../dataset/electricity.csv')\n",
    "df = df.iloc[:, :enc_in+1]\n",
    "# Load the last seq_len entries data as input and converts to tensor\n",
    "x = torch.tensor(df[-seq_len:].drop(labels=['date'], axis=1).values, requires_grad=True).resize(1, seq_len, len(df.columns) - 1).float()\n",
    "# Flips the neural net into inference mode\n",
    "circuit.eval()\n",
    "\n",
    "y = circuit(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a18bb",
   "metadata": {},
   "source": [
    "## ZK Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Files Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b37637c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "import os\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "model_path = os.path.join('network.onnx')\n",
    "compiled_model_path = os.path.join('network.ezkl')\n",
    "pk_path = os.path.join('test.pk')\n",
    "vk_path = os.path.join('test.vk')\n",
    "settings_path = os.path.join('settings.json')\n",
    "srs_path = os.path.join('kzg.srs')\n",
    "witness_path = os.path.join('witness.json')\n",
    "data_path = os.path.join('input.json')\n",
    "proof_path = os.path.join('test.pf')\n",
    "sol_code_path = os.path.join('verify.sol')\n",
    "abi_path = os.path.join('verify.abi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d388ec",
   "metadata": {},
   "source": [
    "#### Convert Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82db373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input.json size: 64.1669921875KB\n",
      "network.onnx size: 1191.4677734375KB\n"
     ]
    }
   ],
   "source": [
    "# Model was trained by 'electricity.sh' and stored into the checkpoint state 'checkpoint.pth'.\n",
    "# Now we need to export the onnx file from this state file with model inputs.\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(circuit,               # model being run\n",
    "                  x,                   # model input (or a tuple for multiple inputs)\n",
    "                  model_path,            # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=15,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "\n",
    "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "# Serialize data into file:\n",
    "json.dump( data, open(data_path, 'w' ))\n",
    "\n",
    "input_size = os.stat(data_path).st_size / 1024\n",
    "onnx_size = os.stat(model_path).st_size / 1024\n",
    "print(\"Input.json size: {}KB\".format(input_size))\n",
    "print(\"network.onnx size: {}KB\".format(onnx_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be271e27",
   "metadata": {},
   "source": [
    "### Setting circuit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4449eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "\n",
    "run_args = ezkl.PyRunArgs()\n",
    "run_args.input_visibility = \"private\"\n",
    "run_args.output_visibility = \"public\"\n",
    "run_args.param_visibility = \"fixed\"\n",
    "run_args.variables = [(\"batch_size\", 1)]\n",
    "# run_args.logrows = 20\n",
    "\n",
    "try:\n",
    "    table_string = ezkl.table(model_path, run_args)\n",
    "#     print(table_string)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+---------------+---------------+-----------+------------+----------------+------------------+---------------+----------------+--------------------+--------------------+------------------------+\n",
      "| mean_error    | median_error  | max_error | min_error  | mean_abs_error | median_abs_error | max_abs_error | min_abs_error  | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+---------------+---------------+-----------+------------+----------------+------------------+---------------+----------------+--------------------+--------------------+------------------------+\n",
      "| -0.0019971626 | 0.00005340576 | 6.5859375 | -5.2851563 | 0.2263001      | 0.00005340576    | 6.5859375     | 0.000030517578 | 0.36669162         | -0.0000028767922   | 0.0005136585           |\n",
      "+---------------+---------------+-----------+------------+----------------+------------------+---------------+----------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=run_args)\n",
    "assert res == True\n",
    "\n",
    "res = ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e11b202",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e7b28aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation time used: 0.7594859087839723 seconds.\n",
      "Current memory size 14085.989 KB, peak memory size 136159.106 KB\n"
     ]
    }
   ],
   "source": [
    "tracemalloc.start()\n",
    "start = timer()\n",
    "\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "assert res == True\n",
    "\n",
    "end = timer()\n",
    "print(\"Compilation time used: {} seconds.\".format(end - start))\n",
    "\n",
    "curr_size, peak_size = tracemalloc.get_traced_memory()\n",
    "print(\"Current memory size {} KB, peak memory size {} KB\".format(round(curr_size / 1024, 3),\n",
    "                                                              round(peak_size / 1024, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0323dc",
   "metadata": {},
   "source": [
    "### Creating the circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae11ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get public srs from kzg ceremony, saved to srs path.\n",
    "try:\n",
    "    os.remove(srs_path)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "res = ezkl.get_srs(srs_path=srs_path, settings_path=settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5e374a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Setup is performed by the application developer, \n",
    "# who then deploys the resulting artifacts to production.\n",
    "\n",
    "# setup the circuit and make sure the keys are generated afterwards. \n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577a100",
   "metadata": {},
   "source": [
    "### Making a proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prove, invoked with ezkl prove at the cli or ezkl.prove() in Python, is called by the prover, often on the client.\n",
    "# import tracemalloc\n",
    "# import numpy as np\n",
    "\n",
    "# tracemalloc.start()\n",
    "# current_memories = []\n",
    "# peak_memories = []\n",
    "# prove_times = []\n",
    "# for i in range(10): \n",
    "#     start = timer()\n",
    "#     res = ezkl.gen_witness(\n",
    "#             data_path, \n",
    "#             compiled_model_path, \n",
    "#             witness_path\n",
    "#           )\n",
    "#     assert os.path.isfile(witness_path)\n",
    "\n",
    "#     # GENERATE A PROOF\n",
    "\n",
    "#     res = ezkl.prove(\n",
    "#             witness_path,\n",
    "#             compiled_model_path,\n",
    "#             pk_path,\n",
    "#             proof_path,\n",
    "#             \"single\",\n",
    "#             srs_path,\n",
    "#         )\n",
    "#     assert os.path.isfile(proof_path)\n",
    "#     end = timer()\n",
    "#     prove_time = end - start\n",
    "\n",
    "#     current, peak = tracemalloc.get_traced_memory()\n",
    "#     current_memories.append(current/(1024*1024))\n",
    "#     peak_memories.append(peak/(1024*1024))\n",
    "#     prove_times.append(prove_time)\n",
    "#     tracemalloc.reset_peak()\n",
    "#     # tracemalloc.clear_traces()\n",
    "#     del current, peak, start, end\n",
    "# print('Average current memory [MB]: {}, average peak memory [MB]: {} +/- {}'.format(\n",
    "#       round(np.mean(current_memories), 4), round(np.mean(peak_memories), 4), \n",
    "#       round(np.std(peak_memories), 4))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbf9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ezkl.gen_witness(\n",
    "        data_path, \n",
    "        compiled_model_path, \n",
    "        witness_path\n",
    "      )\n",
    "assert os.path.isfile(witness_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54450369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average current memory [MB]: 13.6138, average peak memory [MB]: 136.2881 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "# Prove, invoked with ezkl prove at the cli or ezkl.prove() in Python, is called by the prover, often on the client.\n",
    "import tracemalloc\n",
    "import numpy as np\n",
    "\n",
    "tracemalloc.start()\n",
    "current_memories = []\n",
    "peak_memories = []\n",
    "prove_times = []\n",
    "\n",
    "# GENERATE A PROOF\n",
    "\n",
    "res = ezkl.prove(\n",
    "        witness_path,\n",
    "        compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "        \"single\",\n",
    "        srs_path,\n",
    "    )\n",
    "assert os.path.isfile(proof_path)\n",
    "end = timer()\n",
    "prove_time = end - start\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "current_memories.append(current/(1024*1024))\n",
    "peak_memories.append(peak/(1024*1024))\n",
    "prove_times.append(prove_time)\n",
    "tracemalloc.reset_peak()\n",
    "    # tracemalloc.clear_traces()\n",
    "    # del current, peak, start, end\n",
    "print('Average current memory [MB]: {}, average peak memory [MB]: {} +/- {}'.format(\n",
    "      round(np.mean(current_memories), 4), round(np.mean(peak_memories), 4), \n",
    "      round(np.std(peak_memories), 4))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ab53a",
   "metadata": {},
   "source": [
    "### Verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068394b4",
   "metadata": {},
   "source": [
    "#### VERIFY off-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76f00d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified\n",
      "time used: 0.8323131599463522 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "print(\"verified\")\n",
    "end = timer()\n",
    "print(\"time used: {} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2273575",
   "metadata": {},
   "source": [
    "#### VERIFY on-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22fb7d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify.sol size: 84.9794921875KB\n"
     ]
    }
   ],
   "source": [
    "# Create verifier contract\n",
    "res = ezkl.create_evm_verifier(\n",
    "        vk_path=vk_path,\n",
    "        srs_path=srs_path,\n",
    "        settings_path=settings_path,\n",
    "        sol_code_path=sol_code_path,\n",
    "        abi_path=abi_path,\n",
    "    )\n",
    "verifier_size = os.stat(sol_code_path).st_size / 1024\n",
    "print(\"{} size: {}KB\".format(sol_code_path, verifier_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f8fed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. install anvil if you haven't already\n",
    "# cargo install --git https://github.com/foundry-rs/foundry --profile local --locked anvil\n",
    "# 2. spin up a local EVM through anvil in a separate terminal \n",
    "# anvil -p 3030\n",
    "\n",
    "# Deploy the verifier contract onchain\n",
    "sol_code_path = os.path.join(\"verify.sol\")\n",
    "address_path = os.path.join('contractAddr.txt')\n",
    "# assuming anvil is running\n",
    "res = ezkl.deploy_evm(\n",
    "    address_path,\n",
    "    sol_code_path,\n",
    "    'http://127.0.0.1:3030'\n",
    ")\n",
    "\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify proof onchain\n",
    "\n",
    "with open(address_path, 'r') as f:\n",
    "  addr = f.readline()\n",
    "\n",
    "res = ezkl.verify_evm(\n",
    "    proof_path=proof_path,\n",
    "    addr_verifier=addr,\n",
    "    rpc_url='http://127.0.0.1:3030'\n",
    ")\n",
    "\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.json size: 37.968KB\n",
      "network.onnx size: 713.995KB\n",
      "test.pf size: 132.24KB\n",
      "prove time used: 188.903 seconds\n",
      "prove memory used: 136.288 MB\n",
      "verify.sol size: 84.979KB\n",
      "Verifier bytecode size: 21.299KB\n"
     ]
    }
   ],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "\n",
    "input_size = round(os.stat(data_path).st_size / 1024, 3)\n",
    "onnx_size = round(os.stat(model_path).st_size / 1024, 3)\n",
    "print(\"{} size: {}KB\".format(data_path, input_size))\n",
    "print(\"{} size: {}KB\".format(model_path, onnx_size))\n",
    "proof_size = round(os.stat(proof_path).st_size / 1024, 3)\n",
    "print(\"{} size: {}KB\".format(proof_path, proof_size))\n",
    "prove_time = round(np.mean(prove_times), 3)\n",
    "print(\"prove time used: {} seconds\".format(prove_time))\n",
    "prove_mem = round(np.mean(peak_memories), 3)\n",
    "print(\"prove memory used: {} MB\".format(prove_mem))\n",
    "\n",
    "verifier_size = round(os.stat(sol_code_path).st_size / 1024, 3)\n",
    "print(\"{} size: {}KB\".format(sol_code_path, verifier_size))\n",
    "\n",
    "p = Popen([\"solc\", \"--bin\", \"--optimize\", \"verify.sol\"], stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "output, err = p.communicate(b\"input data that is passed to subprocess' stdin\")\n",
    "verifier_code_size = round(sys.getsizeof((output.split(b'\\n')[3])) / 1000, 3)\n",
    "print(\"Verifier bytecode size: {}KB\".format(verifier_code_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e55e8935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Input Size</th>\n",
       "      <th>ONNX Size</th>\n",
       "      <th>Proof Size</th>\n",
       "      <th>Prove Time</th>\n",
       "      <th>Prove Mem</th>\n",
       "      <th>Verifier Size</th>\n",
       "      <th>Bytecode Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>138960</td>\n",
       "      <td>37.968</td>\n",
       "      <td>713.995</td>\n",
       "      <td>132.24</td>\n",
       "      <td>188.903</td>\n",
       "      <td>136.288</td>\n",
       "      <td>84.979</td>\n",
       "      <td>21.299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Parameters  Input Size  ONNX Size  Proof Size  Prove Time  Prove Mem  \\\n",
       "192      138960      37.968    713.995      132.24     188.903    136.288   \n",
       "\n",
       "     Verifier Size  Bytecode Size  \n",
       "192         84.979         21.299  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colums = ['Parameters', 'Input Size', 'ONNX Size', 'Proof Size',\n",
    "          'Prove Time', 'Prove Mem', 'Verifier Size', 'Bytecode Size']\n",
    "stats = [[total_params], [input_size], [onnx_size], [proof_size],\n",
    "        [prove_time], [prove_mem], [verifier_size], [verifier_code_size]]\n",
    "data = dict(zip(colums, stats))\n",
    "index = [seq_len]\n",
    "df = pd.DataFrame(data=data, index=index)\n",
    "output_path='zkml_perf.csv'\n",
    "df.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8fad20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 nodes: downsizing params to 18 logrows 4625160\n",
    "max_mem = 4631932 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9cd9c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4523.37109375"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4631932 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41642774",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4e7253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 nodes\n",
    "max_mem = 2311880 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6784b803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257.6953125"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2311880 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c254855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ef861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8998.2734375"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9214232 / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df3d3d",
   "metadata": {},
   "source": [
    "- 30: Time: 3:35.66 max_mem: 9214232 / 1024\n",
    "- 40: Time: 5:09.51 Max_mem 14993000 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5348c01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14641.6015625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14993000 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c21a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae257702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [\u001b[95m2024-04-06 20:28:54\u001b[0m, ezkl] - \u001b[1;37m\n",
      "\u001b[1;37m | \u001b[0m \n",
      "\u001b[1;37m | \u001b[0m         ███████╗███████╗██╗  ██╗██╗\n",
      "\u001b[1;37m | \u001b[0m         ██╔════╝╚══███╔╝██║ ██╔╝██║\n",
      "\u001b[1;37m | \u001b[0m         █████╗    ███╔╝ █████╔╝ ██║\n",
      "\u001b[1;37m | \u001b[0m         ██╔══╝   ███╔╝  ██╔═██╗ ██║\n",
      "\u001b[1;37m | \u001b[0m         ███████╗███████╗██║  ██╗███████╗\n",
      "\u001b[1;37m | \u001b[0m         ╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝\n",
      "\u001b[1;37m | \u001b[0m \n",
      "\u001b[1;37m | \u001b[0m         -----------------------------------------------------------\n",
      "\u001b[1;37m | \u001b[0m         Easy Zero Knowledge for the Lyrical.\n",
      "\u001b[1;37m | \u001b[0m         -----------------------------------------------------------\n",
      "\u001b[1;37m | \u001b[0m \n",
      "\u001b[1;37m | \u001b[0m         \u001b[0m\n",
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [\u001b[95m2024-04-06 20:28:54\u001b[0m, ezkl::pfsys] - \u001b[1;37mloading proving key from \"test.pk\"\u001b[0m\n",
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [\u001b[95m2024-04-06 20:30:11\u001b[0m, ezkl::pfsys] - \u001b[1;37mdone loading proving key ✅\u001b[0m\n",
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [\u001b[95m2024-04-06 20:30:11\u001b[0m, ezkl::pfsys::srs] - \u001b[1;37mloading srs from \"kzg.srs\"\u001b[0m\n",
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [\u001b[95m2024-04-06 20:30:13\u001b[0m, ezkl::execute] - \u001b[1;37mdownsizing params to 20 logrows\u001b[0m\n",
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [\u001b[95m2024-04-06 20:30:13\u001b[0m, ezkl::pfsys] - \u001b[1;37mproof started...\u001b[0m\n",
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [\u001b[95m2024-04-06 20:30:15\u001b[0m, ezkl::graph::model] - \u001b[1;37mmodel layout...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command terminated by signal 9\n",
      "\tCommand being timed: \"ezkl prove --witness witness.json -M network.ezkl --proof-path test.pf --pk-path test.pk --srs-path kzg.srs\"\n",
      "\tUser time (seconds): 755.69\n",
      "\tSystem time (seconds): 72.55\n",
      "\tPercent of CPU this job got: 224%\n",
      "\tElapsed (wall clock) time (h:mm:ss or m:ss): 6:09.02\n",
      "\tAverage shared text size (kbytes): 0\n",
      "\tAverage unshared data size (kbytes): 0\n",
      "\tAverage stack size (kbytes): 0\n",
      "\tAverage total size (kbytes): 0\n",
      "\tMaximum resident set size (kbytes): 14564584\n",
      "\tAverage resident set size (kbytes): 0\n",
      "\tMajor (requiring I/O) page faults: 13402\n",
      "\tMinor (reclaiming a frame) page faults: 6733350\n",
      "\tVoluntary context switches: 119508\n",
      "\tInvoluntary context switches: 455555\n",
      "\tSwaps: 0\n",
      "\tFile system inputs: 19567880\n",
      "\tFile system outputs: 0\n",
      "\tSocket messages sent: 0\n",
      "\tSocket messages received: 0\n",
      "\tSignals delivered: 0\n",
      "\tPage size (bytes): 4096\n",
      "\tExit status: 0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# /usr/bin/time -v ezkl prove --witness witness.json -M network.ezkl --proof-path test.pf --pk-path test.pk --srs-path=kzg.srs\n",
    "\n",
    "result = subprocess.run(['/usr/bin/time', '-v', 'ezkl', 'prove', '--witness', witness_path, '-M', compiled_model_path, '--proof-path', proof_path, '--pk-path', pk_path, '--srs-path', srs_path])\n",
    "result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc9c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "677d955a7e2fda1ccedeccccaf5b6288055c92ed57fa8a7738e9fddc38d3c4eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
