{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb67701",
   "metadata": {},
   "source": [
    "## Define an LTSF-Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95613ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph main_graph (\\n  %input[FLOAT, batch_sizex96x1]\\n) initializers (\\n  %Linear_Seasonal.bias[FLOAT, 96]\\n  %Linear_Trend.bias[FLOAT, 96]\\n  %onnx::MatMul_52[FLOAT, 96x96]\\n  %onnx::MatMul_53[FLOAT, 96x96]\\n) {\\n  %/decompsition/moving_avg/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/Slice_output_0 = Slice(%input, %/decompsition/moving_avg/Constant_1_output_0, %/decompsition/moving_avg/Constant_2_output_0, %/decompsition/moving_avg/Constant_output_0, %/decompsition/moving_avg/Constant_3_output_0)\\n  %onnx::Tile_13 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/ConstantOfShape_output_0 = ConstantOfShape[value = <Tensor>](%/decompsition/moving_avg/Constant_4_output_0)\\n  %/decompsition/moving_avg/Expand_output_0 = Expand(%/decompsition/moving_avg/Slice_output_0, %/decompsition/moving_avg/ConstantOfShape_output_0)\\n  %/decompsition/moving_avg/Tile_output_0 = Tile(%/decompsition/moving_avg/Expand_output_0, %onnx::Tile_13)\\n  %/decompsition/moving_avg/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/Constant_7_output_0 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/Constant_8_output_0 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/Slice_1_output_0 = Slice(%input, %/decompsition/moving_avg/Constant_6_output_0, %/decompsition/moving_avg/Constant_7_output_0, %/decompsition/moving_avg/Constant_5_output_0, %/decompsition/moving_avg/Constant_8_output_0)\\n  %/decompsition/moving_avg/Constant_9_output_0 = Constant[value = <Tensor>]()\\n  %/decompsition/moving_avg/ConstantOfShape_1_output_0 = ConstantOfShape[value = <Tensor>](%/decompsition/moving_avg/Constant_9_output_0)\\n  %/decompsition/moving_avg/Expand_1_output_0 = Expand(%/decompsition/moving_avg/Slice_1_output_0, %/decompsition/moving_avg/ConstantOfShape_1_output_0)\\n  %/decompsition/moving_avg/Tile_1_output_0 = Tile(%/decompsition/moving_avg/Expand_1_output_0, %onnx::Tile_13)\\n  %/decompsition/moving_avg/Concat_output_0 = Concat[axis = 1](%/decompsition/moving_avg/Tile_output_0, %input, %/decompsition/moving_avg/Tile_1_output_0)\\n  %/decompsition/moving_avg/Transpose_output_0 = Transpose[perm = [0, 2, 1]](%/decompsition/moving_avg/Concat_output_0)\\n  %/decompsition/moving_avg/avg/AveragePool_output_0 = AveragePool[ceil_mode = 0, count_include_pad = 1, kernel_shape = [25], pads = [0, 0], strides = [1]](%/decompsition/moving_avg/Transpose_output_0)\\n  %/decompsition/moving_avg/Transpose_1_output_0 = Transpose[perm = [0, 2, 1]](%/decompsition/moving_avg/avg/AveragePool_output_0)\\n  %/decompsition/Sub_output_0 = Sub(%input, %/decompsition/moving_avg/Transpose_1_output_0)\\n  %/Transpose_output_0 = Transpose[perm = [0, 2, 1]](%/decompsition/Sub_output_0)\\n  %/Linear_Seasonal/MatMul_output_0 = MatMul(%/Transpose_output_0, %onnx::MatMul_52)\\n  %/Linear_Seasonal/Add_output_0 = Add(%Linear_Seasonal.bias, %/Linear_Seasonal/MatMul_output_0)\\n  %/Linear_Trend/MatMul_output_0 = MatMul(%/decompsition/moving_avg/avg/AveragePool_output_0, %onnx::MatMul_53)\\n  %/Linear_Trend/Add_output_0 = Add(%Linear_Trend.bias, %/Linear_Trend/MatMul_output_0)\\n  %/Add_output_0 = Add(%/Linear_Seasonal/Add_output_0, %/Linear_Trend/Add_output_0)\\n  %output = Transpose[perm = [0, 2, 1]](%/Add_output_0)\\n  return %output\\n}'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import onnx\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from models.DLinear import Model as DLinear\n",
    "\n",
    "from data_provider.data_factory import data_provider\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--is_training', type=int, default=1, help='status')\n",
    "parser.add_argument('--train_only', type=bool, default=False, help='perform training on full input dataset without validation and testing')\n",
    "parser.add_argument('--model_id', type=str, default='test', help='model id')\n",
    "parser.add_argument('--model', type=str, default='Autoformer',\n",
    "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, default='custom', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='../dataset/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='electricity.csv', help='data file')\n",
    "parser.add_argument('--features', type=str, default='S',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')\n",
    "\n",
    "\n",
    "# DLinear\n",
    "parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n",
    "# Formers \n",
    "parser.add_argument('--embed_type', type=int, default=0, help='0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding')\n",
    "parser.add_argument('--enc_in', type=int, default=21, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\n",
    "parser.add_argument('--dec_in', type=int, default=21, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=21, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=1, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=100, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='mse', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "parser.add_argument(\"--seed\", type=int, default=2021, help=\"random seed\")\n",
    "parser.add_argument('--test_flop', action='store_true', default=False, help='See utils/tools for usage')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "model = onnx.load('../checkpoints/test_DLinear_custom_ftS_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_test_0/checkpoint.onnx')\n",
    "\n",
    "# Check that the model is well-formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "onnx.helper.printable_graph(model.graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a18bb",
   "metadata": {},
   "source": [
    "## ZK Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5687f6d",
   "metadata": {},
   "source": [
    "### Prepare Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Files Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b37637c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ezkl\n",
    "import tracemalloc\n",
    "import os\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "model_path = os.path.join('network.onnx')\n",
    "compiled_model_path = os.path.join('network.ezkl')\n",
    "pk_path = os.path.join('test.pk')\n",
    "vk_path = os.path.join('test.vk')\n",
    "settings_path = os.path.join('settings.json')\n",
    "srs_path = os.path.join('kzg.srs')\n",
    "witness_path = os.path.join('witness.json')\n",
    "data_path = os.path.join('input.json')\n",
    "proof_path = os.path.join('test.pf')\n",
    "sol_code_path = os.path.join('verify.sol')\n",
    "abi_path = os.path.join('verify.abi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d388ec",
   "metadata": {},
   "source": [
    "#### Convert Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82db373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (Linear): Linear(in_features=720, out_features=24, bias=True)\n",
      ")\n",
      "Input.json size: 13.5732421875KB\n",
      "network.onnx size: 68.064453125KB\n"
     ]
    }
   ],
   "source": [
    "# Model was trained by '/mnt/LTSF-Linear/scripts/EXP-LongForecasting/Linear/electricity.sh' and \n",
    "# stored into the checkpoint state 'checkpoint.pth' in the '/mnt/LTSF-Linear/checkpoints' folder.\n",
    "# Now we need to export the onnx file from this state file with model inputs.\n",
    "\n",
    "seq_len = 720\n",
    "pred_len = 24\n",
    "target = 40\n",
    "\n",
    "configs = Configs(seq_len)\n",
    "circuit = Model(configs)\n",
    "check_point_model = '../checkpoints/checkpoint_{}_24_tg{}.pth'.format(seq_len, target)\n",
    "state_dict = torch.load(check_point_model)\n",
    "circuit.load_state_dict(state_dict)\n",
    "print(circuit)\n",
    "\n",
    "\n",
    "# After training, export to onnx (network.onnx) and create a data file (input.json)\n",
    "x = 10*torch.rand(1,*[seq_len, 1], requires_grad=True)\n",
    "\n",
    "# Flips the neural net into inference mode\n",
    "circuit.eval()\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(circuit,               # model being run\n",
    "                      x,                   # model input (or a tuple for multiple inputs)\n",
    "                      model_path,            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = ['input'],   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "\n",
    "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "# Serialize data into file:\n",
    "json.dump( data, open(data_path, 'w' ))\n",
    "\n",
    "input_size = os.stat(data_path).st_size / 1024\n",
    "onnx_size = os.stat(model_path).st_size / 1024\n",
    "print(\"Input.json size: {}KB\".format(input_size))\n",
    "print(\"network.onnx size: {}KB\".format(onnx_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be271e27",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4449eeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [0s, ezkl] - \u001b[1;37m\n",
      "\u001b[1;37m | \u001b[0m \n",
      "\u001b[1;37m | \u001b[0m         ███████╗███████╗██╗  ██╗██╗\n",
      "\u001b[1;37m | \u001b[0m         ██╔════╝╚══███╔╝██║ ██╔╝██║\n",
      "\u001b[1;37m | \u001b[0m         █████╗    ███╔╝ █████╔╝ ██║\n",
      "\u001b[1;37m | \u001b[0m         ██╔══╝   ███╔╝  ██╔═██╗ ██║\n",
      "\u001b[1;37m | \u001b[0m         ███████╗███████╗██║  ██╗███████╗\n",
      "\u001b[1;37m | \u001b[0m         ╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝\n",
      "\u001b[1;37m | \u001b[0m \n",
      "\u001b[1;37m | \u001b[0m         -----------------------------------------------------------\n",
      "\u001b[1;37m | \u001b[0m         Easy Zero Knowledge for Layers.\n",
      "\u001b[1;37m | \u001b[0m         -----------------------------------------------------------\n",
      "\u001b[1;37m | \u001b[0m \n",
      "\u001b[1;37m | \u001b[0m         \u001b[0m\n",
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [0s, ezkl] - \u001b[1;37mcommand: \n",
      "\u001b[1;37m | \u001b[0m  \u001b[1m{\u001b[0m\u001b[1;37m\n",
      "\u001b[1;37m | \u001b[0m   \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mcommand\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: \u001b[1m{\u001b[0m\u001b[1;37m\n",
      "\u001b[1;37m | \u001b[0m     \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mTable\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: \u001b[1m{\u001b[0m\u001b[1;37m\n",
      "\u001b[1;37m | \u001b[0m       \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34margs\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: \u001b[1m{\u001b[0m\u001b[1;37m\n",
      "\u001b[1;37m | \u001b[0m         \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mbatch_size\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: 1,\n",
      "\u001b[1;37m | \u001b[0m         \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mbits\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: 16,\n",
      "\u001b[1;37m | \u001b[0m         \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34minput_visibility\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: \u001b[32m\"\u001b[0m\u001b[1;37m\u001b[32mPrivate\u001b[0m\u001b[1;37m\u001b[32m\"\u001b[0m\u001b[1;37m,\n",
      "\u001b[1;37m | \u001b[0m         \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mlogrows\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: 17,\n",
      "\u001b[1;37m | \u001b[0m         \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34moutput_visibility\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: \u001b[32m\"\u001b[0m\u001b[1;37m\u001b[32mPublic\u001b[0m\u001b[1;37m\u001b[32m\"\u001b[0m\u001b[1;37m,\n",
      "\u001b[1;37m | \u001b[0m         \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mparam_visibility\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: \u001b[32m\"\u001b[0m\u001b[1;37m\u001b[32mPrivate\u001b[0m\u001b[1;37m\u001b[32m\"\u001b[0m\u001b[1;37m,\n",
      "\u001b[1;37m | \u001b[0m         \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mscale\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: 7,\n",
      "\u001b[1;37m | \u001b[0m         \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mtolerance\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: \u001b[1m{\u001b[0m\u001b[1;37m\n",
      "\u001b[1;37m | \u001b[0m           \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mscales\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: \u001b[1m[\u001b[0m\u001b[1;37m\n",
      "\u001b[1;37m | \u001b[0m             1,\n",
      "\u001b[1;37m | \u001b[0m             1\u001b[1m\n",
      "\u001b[1;37m | \u001b[0m           ]\u001b[0m\u001b[1;37m,\n",
      "\u001b[1;37m | \u001b[0m           \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mval\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: 0.0\u001b[1m\n",
      "\u001b[1;37m | \u001b[0m         }\u001b[0m\u001b[1;37m\u001b[1m\n",
      "\u001b[1;37m | \u001b[0m       }\u001b[0m\u001b[1;37m,\n",
      "\u001b[1;37m | \u001b[0m       \u001b[1;34m\"\u001b[0m\u001b[1;37m\u001b[1;34mmodel\u001b[0m\u001b[1;37m\u001b[1;34m\"\u001b[0m\u001b[1;37m: \u001b[32m\"\u001b[0m\u001b[1;37m\u001b[32mnetwork.onnx\u001b[0m\u001b[1;37m\u001b[32m\"\u001b[0m\u001b[1;37m\u001b[1m\n",
      "\u001b[1;37m | \u001b[0m     }\u001b[0m\u001b[1;37m\u001b[1m\n",
      "\u001b[1;37m | \u001b[0m   }\u001b[0m\u001b[1;37m\u001b[1m\n",
      "\u001b[1;37m | \u001b[0m }\u001b[0m\u001b[1;37m\u001b[0m\n",
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [0s, ezkl::graph::model] - \u001b[1;37mset batch size to 1\u001b[0m\n",
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [0s, ezkl::execute] - \u001b[1;37m\n",
      "\u001b[1;37m | \u001b[0m   \n",
      "\u001b[1;37m | \u001b[0m ┌─────┬────────────────────┬───────────┬──────────────────┬─────────────┬──────────────────┐\n",
      "\u001b[1;37m | \u001b[0m │ idx │ opkind             │ out_scale │ inputs           │ out_dims    │ required_lookups │\n",
      "\u001b[1;37m | \u001b[0m ├─────┼────────────────────┼───────────┼──────────────────┼─────────────┼──────────────────┤\n",
      "\u001b[1;37m | \u001b[0m │ 0   │ Input              │ 7         │                  │ [1, 720, 1] │ []               │\n",
      "\u001b[1;37m | \u001b[0m ├─────┼────────────────────┼───────────┼──────────────────┼─────────────┼──────────────────┤\n",
      "\u001b[1;37m | \u001b[0m │ 1   │ CONST              │ 7         │                  │ [720, 24]   │ []               │\n",
      "\u001b[1;37m | \u001b[0m ├─────┼────────────────────┼───────────┼──────────────────┼─────────────┼──────────────────┤\n",
      "\u001b[1;37m | \u001b[0m │ 2   │ EINSUM akm,kn->anm │ 14        │ [(0, 0), (1, 0)] │ [1, 24, 1]  │ []               │\n",
      "\u001b[1;37m | \u001b[0m ├─────┼────────────────────┼───────────┼──────────────────┼─────────────┼──────────────────┤\n",
      "\u001b[1;37m | \u001b[0m │ 3   │ CONST              │ 7         │                  │ [1, 24, 1]  │ []               │\n",
      "\u001b[1;37m | \u001b[0m ├─────┼────────────────────┼───────────┼──────────────────┼─────────────┼──────────────────┤\n",
      "\u001b[1;37m | \u001b[0m │ 4   │ RESCALED ADD       │ 7         │ [(3, 0), (2, 0)] │ [1, 24, 1]  │ [\"DIV w/ 128\"]   │\n",
      "\u001b[1;37m | \u001b[0m └─────┴────────────────────┴───────────┴──────────────────┴─────────────┴──────────────────┘\u001b[0m\n",
      "\u001b[1;34m[\u001b[0m\u001b[1;34m*\u001b[0m\u001b[1;34m]\u001b[0m [0s, ezkl] - \u001b[1;37msucceeded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ezkl table -M network.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5e374a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 2\n",
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 16.07956880517304 seconds.\n",
      "[ Top 10 ]\n",
      "/usr/lib/python3.10/ast.py:50: size=2278 KiB, count=46892, average=50 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/executing/executing.py:265: size=429 KiB, count=5833, average=75 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/executing/executing.py:236: size=340 KiB, count=3347, average=104 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/executing/executing.py:263: size=231 KiB, count=690, average=343 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/executing/executing.py:227: size=151 KiB, count=5, average=30.3 KiB\n",
      "/usr/lib/python3.10/tracemalloc.py:558: size=81.7 KiB, count=1544, average=54 B\n",
      "/usr/lib/python3.10/sre_compile.py:804: size=75.4 KiB, count=125, average=617 B\n",
      "/usr/lib/python3.10/tracemalloc.py:67: size=54.6 KiB, count=874, average=64 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/IPython/core/compilerop.py:174: size=43.5 KiB, count=450, average=99 B\n",
      "/usr/lib/python3.10/tracemalloc.py:505: size=41.0 KiB, count=741, average=57 B\n"
     ]
    }
   ],
   "source": [
    "# Setup is performed by the application developer, who then deploys the resulting artifacts to production.\n",
    "\n",
    "!RUST_LOG=trace\n",
    "# TODO: Dictionary outputs\n",
    "# Before setup can run, the settings need to be generated with gen-settings\n",
    "#  and optionally calibrate-settings, and the model must be compiled.\n",
    "\n",
    "tracemalloc.start()\n",
    "start = timer()\n",
    "\n",
    "res = ezkl.gen_settings(model_path, settings_path)\n",
    "assert res == True\n",
    "\n",
    "res = await ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
    "assert res == True\n",
    "\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "assert res == True\n",
    "\n",
    "# srs path\n",
    "res = ezkl.get_srs(srs_path, settings_path)\n",
    "\n",
    "# HERE WE SETUP THE CIRCUIT PARAMS\n",
    "# WE GOT KEYS\n",
    "# WE GOT CIRCUIT PARAMETERS\n",
    "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
    "\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "\n",
    "end = timer()\n",
    "print(\"time used: {} seconds.\".format(end - start))\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('lineno')\n",
    "print(\"[ Top 10 ]\")\n",
    "for stat in top_stats[:10]:\n",
    "    print(stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577a100",
   "metadata": {},
   "source": [
    "### Prove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c384cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spawning module 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 2.98009037040174 seconds\n",
      "[ Top 10 ]\n",
      "/usr/lib/python3.10/ast.py:50: size=2278 KiB, count=46892, average=50 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/executing/executing.py:265: size=429 KiB, count=5833, average=75 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/executing/executing.py:236: size=340 KiB, count=3347, average=104 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/executing/executing.py:263: size=231 KiB, count=690, average=343 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/executing/executing.py:227: size=151 KiB, count=5, average=30.3 KiB\n",
      "/usr/lib/python3.10/tracemalloc.py:558: size=81.5 KiB, count=1536, average=54 B\n",
      "/usr/lib/python3.10/sre_compile.py:804: size=75.4 KiB, count=125, average=617 B\n",
      "/usr/lib/python3.10/tracemalloc.py:67: size=54.8 KiB, count=876, average=64 B\n",
      "/mnt/zkpet/venv/lib/python3.10/site-packages/IPython/core/compilerop.py:174: size=43.5 KiB, count=450, average=99 B\n",
      "/usr/lib/python3.10/tracemalloc.py:505: size=42.8 KiB, count=774, average=57 B\n",
      "test.pf size: 20.458984375KB\n"
     ]
    }
   ],
   "source": [
    "# Prove, invoked with ezkl prove at the cli or ezkl.prove() in Python, is called by the prover, often on the client.\n",
    "\n",
    "# the witness data for the claim: an (input, output) pair (x,y) such that model(input) = output.\n",
    "# this pair can be produced from x using the gen-witness command.\n",
    "# now generate the witness file \n",
    "\n",
    "tracemalloc.start()\n",
    "start = timer()\n",
    "res = ezkl.gen_witness(\n",
    "        data_path, \n",
    "        compiled_model_path, \n",
    "        witness_path\n",
    "      )\n",
    "# assert os.path.isfile(witness_path)\n",
    "\n",
    "# GENERATE A PROOF\n",
    "\n",
    "res = ezkl.prove(\n",
    "        witness_path,\n",
    "        compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "        srs_path,\n",
    "        \"single\"\n",
    "    )\n",
    "\n",
    "# print(res)\n",
    "# assert os.path.isfile(proof_path)\n",
    "\n",
    "end = timer()\n",
    "prove_time = end - start\n",
    "print(\"time used: {} seconds\".format(prove_time))\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('lineno')\n",
    "print(\"[ Top 10 ]\")\n",
    "for stat in top_stats[:10]:\n",
    "    print(stat)\n",
    "\n",
    "proof_size = os.stat(proof_path).st_size / 1024\n",
    "print(\"{} size: {}KB\".format(proof_path, proof_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ab53a",
   "metadata": {},
   "source": [
    "### Verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068394b4",
   "metadata": {},
   "source": [
    "#### VERIFY off-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76f00d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified\n",
      "time used: 0.02656630612909794 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "print(\"verified\")\n",
    "end = timer()\n",
    "print(\"time used: {} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2273575",
   "metadata": {},
   "source": [
    "#### VERIFY on-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22fb7d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify.sol size: 53.421875KB\n"
     ]
    }
   ],
   "source": [
    "# Create verifier contract\n",
    "res = ezkl.create_evm_verifier(\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "        settings_path,\n",
    "        sol_code_path,\n",
    "        abi_path,\n",
    "    )\n",
    "verifier_size = os.stat(sol_code_path).st_size / 1024\n",
    "print(\"{} size: {}KB\".format(sol_code_path, verifier_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f8fed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the verifier contract onchain\n",
    "sol_code_path = os.path.join(\"verify.sol\")\n",
    "address_path = os.path.join('contractAddr.txt')\n",
    "# assuming anvil is running\n",
    "res = ezkl.deploy_evm(\n",
    "    address_path,\n",
    "    sol_code_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(address_path, 'r') as f:\n",
    "  addr = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify proof onchain\n",
    "# res = ezkl.verify_evm(\n",
    "#     proof_path,\n",
    "#     addr\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.json size: 13.5732421875KB\n",
      "network.onnx size: 68.064453125KB\n",
      "test.pf size: 20.458984375KB\n",
      "prove time used: 2.98009037040174 seconds\n",
      "verify.sol size: 53.421875KB\n"
     ]
    }
   ],
   "source": [
    "input_size = os.stat(data_path).st_size / 1024\n",
    "onnx_size = os.stat(model_path).st_size / 1024\n",
    "print(\"{} size: {}KB\".format(data_path, input_size))\n",
    "print(\"{} size: {}KB\".format(model_path, onnx_size))\n",
    "proof_size = os.stat(proof_path).st_size / 1024\n",
    "print(\"{} size: {}KB\".format(proof_path, proof_size))\n",
    "print(\"prove time used: {} seconds\".format(prove_time))\n",
    "verifier_size = os.stat(sol_code_path).st_size / 1024\n",
    "print(\"{} size: {}KB\".format(sol_code_path, verifier_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea65a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "677d955a7e2fda1ccedeccccaf5b6288055c92ed57fa8a7738e9fddc38d3c4eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
