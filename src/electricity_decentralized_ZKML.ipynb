{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb67701",
   "metadata": {},
   "source": [
    "## Prepare Models and Inputs\n",
    "\n",
    "Load a `.pth` file from the checkpoints folder; convert the model to `.ONNX`; generate `input.json` from the `csv` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95613ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/zkpet/venv/lib/python3.11/site-packages/torch/_tensor.py:836: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "import pandas as pd\n",
    "import sys, os, json, ezkl\n",
    "sys.path.append(\"..\")\n",
    "from models.DLinear import Model as DLinear\n",
    "from models.Linear import Model as Linear\n",
    "from models.NLinear import Model as NLinear\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(self, seq_len, pred_len):\n",
    "      self.seq_len = seq_len\n",
    "      self.pred_len = pred_len\n",
    "      self.enc_in = 321\n",
    "      self.individual = False\n",
    "\n",
    "model = 'Linear'\n",
    "seq_len = 192\n",
    "pred_len = 24\n",
    "\n",
    "configs = Configs(seq_len, pred_len)\n",
    "match model:\n",
    "  case 'Linear':\n",
    "    circuit = Linear(configs)\n",
    "  case 'DLinear':\n",
    "    circuit = DLinear(configs)\n",
    "  case 'NLinear':\n",
    "    circuit = NLinear(configs)\n",
    "\n",
    "# Totol number of individual homes\n",
    "node_num = 320\n",
    "df = pd.read_csv('../dataset/electricity.csv')\n",
    "\n",
    "for target in range(node_num):\n",
    "  target = str(target)\n",
    "  basepath = '../checkpoints/Electricity_{}_{}_{}_custom_ftS_tg{}_sl{}_ll48_pl{}_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0'\n",
    "  basepath = basepath.format(seq_len, pred_len, model, target, seq_len, pred_len)\n",
    "  check_point_model = os.path.join(basepath, \"checkpoint.pth\")\n",
    "\n",
    "  state_dict = torch.load(check_point_model)\n",
    "  circuit.load_state_dict(state_dict)\n",
    "\n",
    "  total_params = sum(\n",
    "    param.numel() for param in circuit.parameters()\n",
    "  )\n",
    "\n",
    "  # Load the last seq_len entries data as input and converts to tensor\n",
    "  x = torch.tensor(df[target][-seq_len:].values, requires_grad=True).resize(1, seq_len, 1).float()\n",
    "  # Flips the neural net into inference mode\n",
    "  circuit.eval()\n",
    "\n",
    "  y = circuit(x)\n",
    "  model_path = os.path.join(basepath, 'network.onnx')\n",
    "  data_path = os.path.join(basepath, 'input.json')\n",
    "\n",
    "  # Export the model\n",
    "  torch.onnx.export(circuit,               # model being run\n",
    "                        x,                   # model input (or a tuple for multiple inputs)\n",
    "                        model_path,            # where to save the model (can be a file or file-like object)\n",
    "                        export_params=True,        # store the trained parameter weights inside the model file\n",
    "                        opset_version=15,          # the ONNX version to export the model to\n",
    "                        do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                        input_names = ['input'],   # the model's input names\n",
    "                        output_names = ['output'], # the model's output names\n",
    "                        dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                      'output' : {0 : 'batch_size'}})\n",
    "\n",
    "  data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "  data = dict(input_data = [data_array])\n",
    "  # Serialize data into file:\n",
    "  json.dump(data, open(data_path, 'w' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a18bb",
   "metadata": {},
   "source": [
    "## ZK Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Files Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b37637c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, ezkl\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# model_path = os.path.join('network.onnx')\n",
    "compiled_model_path = os.path.join('network.ezkl')\n",
    "pk_path = os.path.join('test.pk')\n",
    "vk_path = os.path.join('test.vk')\n",
    "settings_path = os.path.join('settings.json')\n",
    "srs_path = os.path.join('kzg.srs')\n",
    "witness_path = os.path.join('witness.json')\n",
    "data_path = os.path.join('input.json')\n",
    "proof_path = os.path.join('test.pf')\n",
    "sol_code_path = os.path.join('verify.sol')\n",
    "abi_path = os.path.join('verify.abi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d388ec",
   "metadata": {},
   "source": [
    "#### Convert Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82db373a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input.json size: 0.767578125KB\n",
      "network.onnx size: 9.5595703125KB\n"
     ]
    }
   ],
   "source": [
    "# Model was trained by 'electricity.sh' and stored into the checkpoint state 'checkpoint.pth'.\n",
    "# Now we need to export the onnx file from this state file with model inputs.\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(circuit,               # model being run\n",
    "                      x,                   # model input (or a tuple for multiple inputs)\n",
    "                      model_path,            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = ['input'],   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "\n",
    "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
    "\n",
    "data = dict(input_data = [data_array])\n",
    "\n",
    "# Serialize data into file:\n",
    "json.dump( data, open(data_path, 'w' ))\n",
    "\n",
    "input_size = os.stat(data_path).st_size / 1024\n",
    "onnx_size = os.stat(model_path).st_size / 1024\n",
    "print(\"Input.json size: {}KB\".format(input_size))\n",
    "print(\"network.onnx size: {}KB\".format(onnx_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be271e27",
   "metadata": {},
   "source": [
    "### Set Circuit Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816450dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+-------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error  | median_error | max_error | min_error  | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+-------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| -0.30433145 | 3.5317383    | 3.5317383 | -2.9389648 | 1.1039734      | 3.5317383        | 3.5317383     | 0.07714844    | 2.010033           | -0.00010244648     | 0.00027499985          |\n",
      "+-------------+--------------+-----------+------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('network.onnx')\n",
    "settings_path = os.path.join('settings.json')\n",
    "data_path = os.path.join('input.json')\n",
    "\n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"private\"\n",
    "py_run_args.output_visibility = \"public\"\n",
    "py_run_args.param_visibility = \"fixed\" # \"fixed\" for params means that the committed to params are used for all proofs\n",
    "\n",
    "# run_args.variables = [(\"batch_size\", 1)]\n",
    "# run_args.logrows = 20\n",
    "\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "assert res == True\n",
    "\n",
    "res = ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4449eeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "┌─────┬─────────────────────────────────────────────────────────────────────────────────────────────────────┬───────────┬──────────────────┬────────────┐\n",
      "│ idx │ opkind                                                                                              │ out_scale │ inputs           │ out_dims   │\n",
      "├─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼──────────────────┼────────────┤\n",
      "│ 0   │ Input                                                                                               │ 7         │                  │ [1, 96, 1] │\n",
      "├─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼──────────────────┼────────────┤\n",
      "│ 1   │ CONST (scale=7)                                                                                     │ 7         │                  │ [96, 24]   │\n",
      "├─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼──────────────────┼────────────┤\n",
      "│ 2   │ REBASED (div=128.0, rebasing_op=DIV (denom=128, use_range_check_for_int=true)) (EINSUM akm,kn->anm) │ 7         │ [(0, 0), (1, 0)] │ [1, 24, 1] │\n",
      "├─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼──────────────────┼────────────┤\n",
      "│ 3   │ CONST (scale=7)                                                                                     │ 7         │                  │ [1, 24, 1] │\n",
      "├─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────┼──────────────────┼────────────┤\n",
      "│ 4   │ ADD                                                                                                 │ 7         │ [(3, 0), (2, 0)] │ [1, 24, 1] │\n",
      "└─────┴─────────────────────────────────────────────────────────────────────────────────────────────────────┴───────────┴──────────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    table_string = ezkl.table(model_path, py_run_args)\n",
    "    print(table_string)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad42bbf",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0952a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation time used: 0.008013301063328981 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "assert res == True\n",
    "\n",
    "end = timer()\n",
    "print(\"Compilation time used: {} seconds.\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29215994",
   "metadata": {},
   "source": [
    "### Creating the Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5cfcb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get public srs from kzg ceremony, saved to srs path. \n",
    "res = ezkl.get_srs(srs_path=srs_path, settings_path=settings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e374a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 0.559538563946262 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "# setup the circuit and make sure the keys are generated afterwards. \n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "\n",
    "end = timer()\n",
    "print(\"time used: {} seconds.\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577a100",
   "metadata": {},
   "source": [
    "### Generate a Proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c384cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average current memory [MB]: 66.7516, average peak memory [MB]: 73.2288 +/- 19.3885\n"
     ]
    }
   ],
   "source": [
    "# Prove, invoked with ezkl prove at the cli or ezkl.prove() in Python, is called by the prover, often on the client.\n",
    "import tracemalloc\n",
    "import numpy as np\n",
    "\n",
    "tracemalloc.start()\n",
    "current_memories = []\n",
    "peak_memories = []\n",
    "prove_times = []\n",
    "for i in range(10): \n",
    "    start = timer()\n",
    "    res = ezkl.gen_witness(\n",
    "            data_path,\n",
    "            compiled_model_path, \n",
    "            witness_path\n",
    "          )\n",
    "    assert os.path.isfile(witness_path)\n",
    "\n",
    "    # GENERATE A PROOF\n",
    "\n",
    "    res = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "            \"single\",\n",
    "            srs_path,\n",
    "        )\n",
    "    assert os.path.isfile(proof_path)\n",
    "    end = timer()\n",
    "    prove_time = end - start\n",
    "\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    current_memories.append(current/(1024*1024))\n",
    "    peak_memories.append(peak/(1024*1024))\n",
    "    prove_times.append(prove_time)\n",
    "    tracemalloc.reset_peak()\n",
    "    # tracemalloc.clear_traces()\n",
    "    del current, peak, start, end\n",
    "print('Average current memory [MB]: {}, average peak memory [MB]: {} +/- {}'.format(\n",
    "      round(np.mean(current_memories), 4), round(np.mean(peak_memories), 4), \n",
    "      round(np.std(peak_memories), 4))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ab53a",
   "metadata": {},
   "source": [
    "### Verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068394b4",
   "metadata": {},
   "source": [
    "#### VERIFY off-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76f00d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified\n",
      "time used: 0.01260763300160761 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path,\n",
    "        srs_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "print(\"verified\")\n",
    "end = timer()\n",
    "print(\"time used: {} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2273575",
   "metadata": {},
   "source": [
    "#### VERIFY on-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22fb7d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify.sol size: 60.0341796875KB\n"
     ]
    }
   ],
   "source": [
    "# Create verifier contract\n",
    "res = ezkl.create_evm_verifier(\n",
    "        srs_path=srs_path, \n",
    "        vk_path=vk_path,\n",
    "        sol_code_path=sol_code_path,\n",
    "        settings_path=settings_path\n",
    "    )\n",
    "verifier_size = os.stat(sol_code_path).st_size / 1024\n",
    "print(\"{} size: {}KB\".format(sol_code_path, verifier_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f8fed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. install anvil if you haven't already\n",
    "# cargo install --git https://github.com/foundry-rs/foundry --profile local --locked anvil\n",
    "# 2. spin up a local EVM through anvil in a separate terminal \n",
    "# anvil -p 3030\n",
    "\n",
    "# Deploy the verifier contract onchain\n",
    "sol_code_path = os.path.join(\"verify.sol\")\n",
    "address_path = os.path.join('contractAddr.txt')\n",
    "\n",
    "res = ezkl.deploy_evm(\n",
    "    address_path,\n",
    "    sol_code_path,\n",
    "    'http://127.0.0.1:3030'\n",
    ")\n",
    "\n",
    "assert res == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify proof onchain\n",
    "try:\n",
    "  with open(address_path, 'r') as f:\n",
    "    addr = f.readline()\n",
    "\n",
    "    res = ezkl.verify_evm(\n",
    "        proof_path=proof_path,\n",
    "        addr_verifier=addr,\n",
    "        rpc_url='http://127.0.0.1:3030'\n",
    "    )\n",
    "\n",
    "  assert res == True\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.json size: 0.768KB\n",
      "network.onnx size: 9.56KB\n",
      "test.pf size: 15.336KB\n",
      "prove time used: 0.62 seconds\n",
      "prove memory used: 73.229 MB\n",
      "verify.sol size: 60.034KB\n",
      "Verifier bytecode size: 14.729KB\n"
     ]
    }
   ],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "\n",
    "input_size = round(os.stat(data_path).st_size / 1024, 3)\n",
    "onnx_size = round(os.stat(model_path).st_size / 1024, 3)\n",
    "print(\"{} size: {}KB\".format(data_path, input_size))\n",
    "print(\"{} size: {}KB\".format(model_path, onnx_size))\n",
    "proof_size = round(os.stat(proof_path).st_size / 1024, 3)\n",
    "print(\"{} size: {}KB\".format(proof_path, proof_size))\n",
    "prove_time = round(np.mean(prove_times), 3)\n",
    "print(\"prove time used: {} seconds\".format(prove_time))\n",
    "prove_mem = round(np.mean(peak_memories), 3)\n",
    "print(\"prove memory used: {} MB\".format(prove_mem))\n",
    "\n",
    "verifier_size = round(os.stat(sol_code_path).st_size / 1024, 3)\n",
    "print(\"{} size: {}KB\".format(sol_code_path, verifier_size))\n",
    "\n",
    "p = Popen([\"solc\", \"--bin\", \"--optimize\", \"verify.sol\"], stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "output, err = p.communicate(b\"input data that is passed to subprocess' stdin\")\n",
    "verifier_code_size = round(sys.getsizeof((output.split(b'\\n')[3])) / 1000, 3)\n",
    "print(\"Verifier bytecode size: {}KB\".format(verifier_code_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "175f3acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Input Size</th>\n",
       "      <th>ONNX Size</th>\n",
       "      <th>Proof Size</th>\n",
       "      <th>Prove Time</th>\n",
       "      <th>Prove Mem</th>\n",
       "      <th>Verifier Size</th>\n",
       "      <th>Bytecode Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2328</td>\n",
       "      <td>0.768</td>\n",
       "      <td>9.56</td>\n",
       "      <td>15.336</td>\n",
       "      <td>0.62</td>\n",
       "      <td>73.229</td>\n",
       "      <td>60.034</td>\n",
       "      <td>14.729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Parameters  Input Size  ONNX Size  Proof Size  Prove Time  Prove Mem  \\\n",
       "96        2328       0.768       9.56      15.336        0.62     73.229   \n",
       "\n",
       "    Verifier Size  Bytecode Size  \n",
       "96         60.034         14.729  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colums = ['Parameters', 'Input Size', 'ONNX Size', 'Proof Size',\n",
    "          'Prove Time', 'Prove Mem', 'Verifier Size', 'Bytecode Size']\n",
    "stats = [[total_params], [input_size], [onnx_size], [proof_size],\n",
    "        [prove_time], [prove_mem], [verifier_size], [verifier_code_size]]\n",
    "data = dict(zip(colums, stats))\n",
    "index = [seq_len]\n",
    "df = pd.DataFrame(data=data, index=index)\n",
    "output_path='zkml_perf.csv'\n",
    "df.to_csv(output_path, mode='a', header=not os.path.exists(output_path))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "677d955a7e2fda1ccedeccccaf5b6288055c92ed57fa8a7738e9fddc38d3c4eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
